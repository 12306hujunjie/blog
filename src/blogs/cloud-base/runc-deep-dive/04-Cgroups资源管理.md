---
title: Cgroups èµ„æºç®¡ç†
date: 2025-08-04
tags:
 - runc
 - äº‘åŸç”Ÿ
 - Cgroups
categories:
 - äº‘åŸç”Ÿ
sidebar: auto
---

# Cgroups èµ„æºç®¡ç†

> **ç³»åˆ—å¯¼èˆªï¼š** [runc å®¹å™¨è¿è¡Œæ—¶æ·±åº¦è§£æç³»åˆ—](./README.md) â†’ ç¬¬å››ç¯‡ï¼šCgroups èµ„æºç®¡ç†  
> **ä¸Šä¸€ç¯‡ï¼š** [Namespaceéš”ç¦»å®ç°](./03-Namespaceéš”ç¦»å®ç°.md)  
> **æœ€åæ›´æ–°ï¼š** 2024

## æ¦‚è¿°

æœ¬æ–‡æ·±å…¥åˆ†æ runc å¦‚ä½•åˆ©ç”¨ Linux Cgroups å®ç°å®¹å™¨èµ„æºç®¡ç†å’Œé™åˆ¶ã€‚Cgroups æ˜¯å®¹å™¨èµ„æºéš”ç¦»çš„æ ¸å¿ƒæœºåˆ¶ï¼Œèƒ½å¤Ÿç²¾ç¡®æ§åˆ¶å®¹å™¨å¯¹ CPUã€å†…å­˜ã€I/O ç­‰èµ„æºçš„ä½¿ç”¨ã€‚

## ğŸ¯ å­¦ä¹ ç›®æ ‡

å®Œæˆæœ¬æ¨¡å—åï¼Œä½ å°†èƒ½å¤Ÿï¼š
- æ·±å…¥ç†è§£ Linux Cgroups çš„æ ¸å¿ƒæ¦‚å¿µå’Œå±‚æ¬¡ç»“æ„
- æŒæ¡ cgroups v1 å’Œ v2 çš„æ¶æ„å·®å¼‚å’Œå®ç°åŸç†
- ç†è§£ CPUã€å†…å­˜ã€IOã€è®¾å¤‡ç­‰èµ„æºæ§åˆ¶æœºåˆ¶
- æŒæ¡ runc ä¸­èµ„æºé™åˆ¶çš„é…ç½®å’Œåº”ç”¨æµç¨‹
- å…·å¤‡èµ„æºç›‘æ§ã€ç»Ÿè®¡å’Œæ€§èƒ½è°ƒä¼˜çš„å®è·µèƒ½åŠ›

## 1. Cgroups åŸºç¡€æ¦‚å¿µ

### 1.1 ä»€ä¹ˆæ˜¯ Cgroupsï¼Ÿ

**Cgroups (Control Groups)** æ˜¯ Linux å†…æ ¸æä¾›çš„èµ„æºç®¡ç†å’Œéš”ç¦»æœºåˆ¶ï¼Œå…è®¸å¯¹è¿›ç¨‹ç»„è¿›è¡Œèµ„æºé™åˆ¶ã€ä¼˜å…ˆçº§åˆ†é…å’Œèµ„æºä½¿ç”¨ç»Ÿè®¡ã€‚

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ç‰©ç†æœºå™¨                     â”‚
â”‚  CPU: 8æ ¸   Memory: 16GB   Disk: 1TB          â”‚
â””â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 â”‚                    â”‚
 â–¼                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   å®¹å™¨ A        â”‚  â”‚        å®¹å™¨ B               â”‚
â”‚ CPU: 2æ ¸ (25%)  â”‚  â”‚    CPU: 4æ ¸ (50%)          â”‚
â”‚ Memory: 4GB     â”‚  â”‚    Memory: 8GB             â”‚
â”‚ IO: 100MB/s     â”‚  â”‚    IO: 200MB/s             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â–²                        â–²
   cgroup-a                 cgroup-b
```

**æ ¸å¿ƒåŠŸèƒ½**ï¼š
- ğŸ¯ **èµ„æºé™åˆ¶**: é™åˆ¶è¿›ç¨‹ç»„ä½¿ç”¨çš„èµ„æºä¸Šé™
- âš–ï¸ **ä¼˜å…ˆçº§åˆ†é…**: åˆ†é…ä¸åŒçš„èµ„æºæƒé‡
- ğŸ“Š **èµ„æºç»Ÿè®¡**: ç›‘æ§å’Œç»Ÿè®¡èµ„æºä½¿ç”¨æƒ…å†µ
- ğŸ”§ **èµ„æºæ§åˆ¶**: åŠ¨æ€è°ƒæ•´èµ„æºé…ç½®

### 1.2 Cgroups å±‚æ¬¡ç»“æ„

```
/sys/fs/cgroup/         â† cgroup æ–‡ä»¶ç³»ç»Ÿæ ¹ç›®å½•
â”œâ”€â”€ system.slice/       â† systemd åˆ›å»ºçš„ç³»ç»ŸæœåŠ¡
â”‚   â”œâ”€â”€ cgroup.procs    â† è¿›ç¨‹åˆ—è¡¨
â”‚   â”œâ”€â”€ cpu.shares      â† CPU æƒé‡
â”‚   â””â”€â”€ memory.limit_in_bytes â† å†…å­˜é™åˆ¶
â”œâ”€â”€ user.slice/         â† ç”¨æˆ·ä¼šè¯
â””â”€â”€ machine.slice/      â† è™šæ‹Ÿæœºå’Œå®¹å™¨
    â””â”€â”€ docker-abc123.scope/
        â”œâ”€â”€ cgroup.procs
        â”œâ”€â”€ cpu.cfs_quota_us
        â”œâ”€â”€ cpu.cfs_period_us
        â”œâ”€â”€ memory.limit_in_bytes
        â”œâ”€â”€ memory.usage_in_bytes
        â””â”€â”€ blkio.throttle.read_bps_device
```

**å±‚æ¬¡ç»“æ„ç‰¹ç‚¹**ï¼š
- ğŸŒ³ **æ ‘å½¢ç»“æ„**: å­ cgroup ç»§æ‰¿çˆ¶ cgroup çš„å±æ€§
- ğŸ‘¥ **è¿›ç¨‹å½’å±**: æ¯ä¸ªè¿›ç¨‹å±äºä¸”ä»…å±äºä¸€ä¸ª cgroup
- ğŸ“‹ **æ§åˆ¶å™¨**: æ¯ä¸ªæ§åˆ¶å™¨ç‹¬ç«‹ç®¡ç†ç‰¹å®šç±»å‹èµ„æº

## 2. Cgroups v1 vs v2 æ¶æ„å·®å¼‚

### 2.1 æ¶æ„å¯¹æ¯”å›¾

#### Cgroups v1 (å¤šå±‚æ¬¡æ¶æ„)

```
/sys/fs/cgroup/
â”œâ”€â”€ cpu/              â† CPU æ§åˆ¶å™¨ç‹¬ç«‹å±‚æ¬¡
â”‚   â”œâ”€â”€ system/
â”‚   â””â”€â”€ docker/
â”‚       â””â”€â”€ container1/
â”œâ”€â”€ memory/           â† å†…å­˜æ§åˆ¶å™¨ç‹¬ç«‹å±‚æ¬¡  
â”‚   â”œâ”€â”€ system/
â”‚   â””â”€â”€ docker/
â”‚       â””â”€â”€ container1/
â”œâ”€â”€ blkio/            â† IO æ§åˆ¶å™¨ç‹¬ç«‹å±‚æ¬¡
â”‚   â”œâ”€â”€ system/
â”‚   â””â”€â”€ docker/
â”‚       â””â”€â”€ container1/
â””â”€â”€ devices/          â† è®¾å¤‡æ§åˆ¶å™¨ç‹¬ç«‹å±‚æ¬¡
    â”œâ”€â”€ system/
    â””â”€â”€ docker/
        â””â”€â”€ container1/
```

#### Cgroups v2 (ç»Ÿä¸€å±‚æ¬¡æ¶æ„)

```
/sys/fs/cgroup/              â† ç»Ÿä¸€æ–‡ä»¶ç³»ç»Ÿ
â”œâ”€â”€ cgroup.controllers       â† å¯ç”¨æ§åˆ¶å™¨åˆ—è¡¨
â”œâ”€â”€ cgroup.subtree_control   â† å¯ç”¨çš„å­æ§åˆ¶å™¨
â”œâ”€â”€ system.slice/
â”‚   â”œâ”€â”€ cpu.weight          â† æ‰€æœ‰æ§åˆ¶å™¨æ–‡ä»¶
â”‚   â”œâ”€â”€ memory.max          â† éƒ½åœ¨åŒä¸€ç›®å½•
â”‚   â”œâ”€â”€ io.max
â”‚   â””â”€â”€ cgroup.procs
â””â”€â”€ machine.slice/
    â””â”€â”€ docker-abc123.scope/
        â”œâ”€â”€ cpu.weight
        â”œâ”€â”€ memory.max
        â”œâ”€â”€ io.max
        â””â”€â”€ cgroup.procs
```

### 2.2 æ ¸å¿ƒå·®å¼‚å¯¹æ¯”

| ç‰¹æ€§ | Cgroups v1 | Cgroups v2 |
|------|------------|------------|
| **å±‚æ¬¡ç»“æ„** | å¤šä¸ªç‹¬ç«‹å±‚æ¬¡ | ç»Ÿä¸€å±‚æ¬¡ç»“æ„ |
| **æ§åˆ¶å™¨ç®¡ç†** | æ¯ä¸ªæ§åˆ¶å™¨ç‹¬ç«‹æŒ‚è½½ | æ‰€æœ‰æ§åˆ¶å™¨ç»Ÿä¸€ç®¡ç† |
| **CPUæƒé‡** | `cpu.shares` (2-262144) | `cpu.weight` (1-10000) |
| **å†…å­˜äº¤æ¢** | `memory.memsw.limit_in_bytes` | `memory.swap.max` |
| **IOæ§åˆ¶** | `blkio.*` æ¥å£ | `io.*` æ¥å£ |
| **è®¾å¤‡æ§åˆ¶** | ç™½åå•æœºåˆ¶ | eBPF ç¨‹åº |
| **å†…å­˜å›æ”¶** | å¤æ‚çš„é¡µé¢å›æ”¶ | ç»Ÿä¸€çš„å†…å­˜å›æ”¶ç­–ç•¥ |
| **PSIæ”¯æŒ** | ä¸æ”¯æŒ | å†…ç½®å‹åŠ›å¤±é€Ÿä¿¡æ¯ |

### 2.3 runc çš„å®ç°é€‚é…

runc é€šè¿‡æŠ½è±¡æ¥å£åŒæ—¶æ”¯æŒä¸¤ä¸ªç‰ˆæœ¬ï¼š

```go
// ç»Ÿä¸€çš„ Manager æ¥å£
type Manager interface {
    Apply(pid int) error           // å°†è¿›ç¨‹åŠ å…¥ cgroup
    GetPids() ([]int, error)       // è·å– cgroup ä¸­çš„è¿›ç¨‹åˆ—è¡¨
    GetAllPids() ([]int, error)    // è·å–åŒ…æ‹¬å­ cgroup çš„æ‰€æœ‰è¿›ç¨‹
    GetStats() (*Stats, error)     // è·å–èµ„æºä½¿ç”¨ç»Ÿè®¡
    Freeze(state FreezerState) error // å†»ç»“/è§£å†»è¿›ç¨‹
    Destroy() error               // é”€æ¯ cgroup
    Set(r *Resources) error       // è®¾ç½®èµ„æºé™åˆ¶
    GetPaths() map[string]string  // è·å– cgroup è·¯å¾„
}

// ç‰ˆæœ¬æ£€æµ‹å’Œç®¡ç†å™¨åˆ›å»º
func NewManager(config *configs.Config) (Manager, error) {
    if cgroups.IsCgroup2UnifiedMode() {
        // ä½¿ç”¨ v2 ç®¡ç†å™¨
        return fs2.NewManager(config, path)
    } else {
        // ä½¿ç”¨ v1 ç®¡ç†å™¨  
        return fs.NewManager(config, paths)
    }
}
```

## 3. æ ¸å¿ƒèµ„æºæ§åˆ¶æœºåˆ¶

### 3.1 CPU èµ„æºæ§åˆ¶

#### A. CPU æƒé‡æ§åˆ¶ (ç›¸å¯¹æƒé‡)

**Cgroups v1 å®ç°**ï¼š

```go
// CPU æƒé‡è®¾ç½® (cpu.shares)
func (s *CpuGroup) Set(path string, r *cgroups.Resources) error {
    if r.CpuShares != 0 {
        // èŒƒå›´: 2-262144ï¼Œé»˜è®¤: 1024
        if err := cgroups.WriteFile(path, "cpu.shares", 
            strconv.FormatUint(r.CpuShares, 10)); err != nil {
            return fmt.Errorf("failed to set cpu.shares: %w", err)
        }
    }
    return nil
}
```

**Cgroups v2 å®ç°**ï¼š

```go
// CPU æƒé‡è®¾ç½® (cpu.weight)  
func setCPU(dirPath string, r *cgroups.Resources) error {
    if r.CpuWeight != 0 {
        // èŒƒå›´: 1-10000ï¼Œé»˜è®¤: 100
        if err := cgroups.WriteFile(dirPath, "cpu.weight", 
            strconv.FormatUint(r.CpuWeight, 10)); err != nil {
            return fmt.Errorf("failed to set cpu.weight: %w", err)
        }
    }
    return nil
}

// v1 shares åˆ° v2 weight çš„è½¬æ¢
func convertSharesToWeight(shares uint64) uint64 {
    if shares == 0 {
        return 0
    }
    // weight = ((shares - 2) * 9999) / 262142 + 1
    return ((shares - 2) * 9999) / 262142 + 1
}
```

**æƒé‡è®¡ç®—ç¤ºä¾‹**ï¼š

```
åœºæ™¯: 3ä¸ªå®¹å™¨ç«äº‰ CPU
å®¹å™¨A: cpu.shares = 1024 (é»˜è®¤)
å®¹å™¨B: cpu.shares = 512  (ä¸€åŠæƒé‡)  
å®¹å™¨C: cpu.shares = 2048 (ä¸¤å€æƒé‡)

æ€»æƒé‡ = 1024 + 512 + 2048 = 3584

CPU åˆ†é…æ¯”ä¾‹:
å®¹å™¨A: 1024/3584 = 28.6%
å®¹å™¨B: 512/3584  = 14.3%  
å®¹å™¨C: 2048/3584 = 57.1%
```

#### B. CPU é…é¢æ§åˆ¶ (ç¡¬é™åˆ¶)

```go
// CFS è°ƒåº¦å™¨é…é¢è®¾ç½®
func setCPUQuota(path string, quota int64, period uint64) error {
    // è®¾ç½®è°ƒåº¦å‘¨æœŸ (é»˜è®¤ 100ms = 100,000Î¼s)
    if period != 0 {
        if err := cgroups.WriteFile(path, "cpu.cfs_period_us", 
            strconv.FormatUint(period, 10)); err != nil {
            return err
        }
    }
    
    // è®¾ç½®é…é¢ (æ¯ä¸ªå‘¨æœŸå†…å¯ä½¿ç”¨çš„ CPU æ—¶é—´)
    if quota != 0 {
        if err := cgroups.WriteFile(path, "cpu.cfs_quota_us", 
            strconv.FormatInt(quota, 10)); err != nil {
            return err
        }
    }
    
    return nil
}
```

**é…é¢è®¡ç®—ç¤ºä¾‹**ï¼š

```bash
# é™åˆ¶å®¹å™¨ä½¿ç”¨ 1.5 ä¸ª CPU æ ¸å¿ƒ
echo 100000 > cpu.cfs_period_us    # å‘¨æœŸ 100ms
echo 150000 > cpu.cfs_quota_us     # é…é¢ 150ms

# é™åˆ¶ä½¿ç”¨ 50% çš„å•æ ¸ CPU
echo 100000 > cpu.cfs_period_us    # å‘¨æœŸ 100ms  
echo 50000  > cpu.cfs_quota_us     # é…é¢ 50ms

# é…é¢è®¡ç®—å…¬å¼:
# CPUæ ¸å¿ƒæ•° = quota / period
# 1.5 æ ¸ = 150000 / 100000 = 1.5
# 0.5 æ ¸ = 50000 / 100000 = 0.5
```

#### C. CPU çªå‘æ§åˆ¶ (Burst)

```go
// CPU çªå‘é™åˆ¶ (è¾ƒæ–°çš„å†…æ ¸ç‰¹æ€§)
func setCPUBurst(path string, burst *uint64) error {
    if burst != nil {
        // å…è®¸çŸ­æœŸå†…è¶…è¿‡é…é¢ä½¿ç”¨çš„ CPU æ—¶é—´
        if err := cgroups.WriteFile(path, "cpu.cfs_burst_us", 
            strconv.FormatUint(*burst, 10)); err != nil {
            // å¿½ç•¥ä¸æ”¯æŒçš„å†…æ ¸
            if !os.IsNotExist(err) {
                return err
            }
        }
    }
    return nil
}
```

### 3.2 å†…å­˜èµ„æºæ§åˆ¶

#### A. å†…å­˜é™åˆ¶è®¾ç½®

```go
// å†…å­˜é™åˆ¶çš„å¤æ‚è®¾ç½®é€»è¾‘
func setMemoryAndSwap(path string, r *cgroups.Resources) error {
    // å…³é”®: äº¤æ¢ç©ºé—´é™åˆ¶å¿…é¡» >= å†…å­˜é™åˆ¶
    if r.Memory != 0 && r.MemorySwap != 0 {
        curLimit, err := fscommon.GetCgroupParamUint(path, cgroupMemoryLimit)
        if err != nil {
            return err
        }
        
        // æ ¹æ®å½“å‰å€¼å†³å®šè®¾ç½®é¡ºåº
        if r.MemorySwap == -1 || curLimit < uint64(r.MemorySwap) {
            // æƒ…å†µ1: å…ˆè®¾ç½®äº¤æ¢ï¼Œå†è®¾ç½®å†…å­˜
            if err := setSwap(path, r.MemorySwap); err != nil {
                return err
            }
            return setMemory(path, r.Memory)
        }
    }
    
    // æƒ…å†µ2: æ­£å¸¸é¡ºåº - å…ˆå†…å­˜ï¼Œåäº¤æ¢
    if err := setMemory(path, r.Memory); err != nil {
        return err
    }
    return setSwap(path, r.MemorySwap)
}

func setMemory(path string, limit int64) error {
    if limit == 0 {
        return nil
    }
    
    err := cgroups.WriteFile(path, cgroupMemoryLimit, 
        strconv.FormatInt(limit, 10))
    
    // EBUSY è¡¨ç¤ºæ–°é™åˆ¶ä½äºå½“å‰ä½¿ç”¨é‡
    if errors.Is(err, unix.EBUSY) {
        usage, _ := fscommon.GetCgroupParamUint(path, cgroupMemoryUsage)
        max, _ := fscommon.GetCgroupParamUint(path, cgroupMemoryMaxUsage)
        return fmt.Errorf("cannot set memory limit to %d: current usage %d, peak usage %d", 
            limit, usage, max)
    }
    
    return err
}
```

#### B. Cgroups v2 å†…å­˜ç®¡ç†

```go
// v2 çš„å†…å­˜ç®¡ç†æ›´åŠ ç»Ÿä¸€å’Œç®€åŒ–
func setMemory(dirPath string, r *cgroups.Resources) error {
    // æ£€æŸ¥å½“å‰å†…å­˜ä½¿ç”¨ï¼Œé¿å…è®¾ç½®è¿‡ä½çš„é™åˆ¶
    if err := CheckMemoryUsage(dirPath, r); err != nil {
        return err
    }
    
    // v2 ä¸­äº¤æ¢ç©ºé—´é™åˆ¶ä¸åŒ…å«å†…å­˜
    swap, err := cgroups.ConvertMemorySwapToCgroupV2Value(r.MemorySwap, r.Memory)
    if err != nil {
        return err
    }
    
    // è®¾ç½®äº¤æ¢é™åˆ¶
    if swapStr := numToStr(swap); swapStr != "" {
        if err := cgroups.WriteFile(dirPath, "memory.swap.max", swapStr); err != nil {
            // å¦‚æœ swap æœªå¯ç”¨ï¼Œé™é»˜å¿½ç•¥é”™è¯¯
            if !(errors.Is(err, os.ErrNotExist) && (swapStr == "max" || swapStr == "0")) {
                return err
            }
        }
    }
    
    // è®¾ç½®å†…å­˜é™åˆ¶
    if val := numToStr(r.Memory); val != "" {
        if err := cgroups.WriteFile(dirPath, "memory.max", val); err != nil {
            return err
        }
    }
    
    return nil
}

// å†…å­˜äº¤æ¢å€¼è½¬æ¢ (v1 -> v2)
func ConvertMemorySwapToCgroupV2Value(memorySwap, memory int64) (int64, error) {
    // v1: memory.memsw.limit_in_bytes åŒ…å«å†…å­˜+äº¤æ¢æ€»é‡
    // v2: memory.swap.max åªåŒ…å«äº¤æ¢ç©ºé—´
    if memorySwap == -1 {
        return -1, nil  // æ— é™åˆ¶
    }
    if memorySwap > 0 && memory > 0 {
        return memorySwap - memory, nil  // å‡å»å†…å­˜éƒ¨åˆ†
    }
    return memorySwap, nil
}
```

#### C. å†…å­˜å›æ”¶ç­–ç•¥

```go
// å†…å­˜äº¤æ¢å€¾å‘æ€§è®¾ç½®
func setSwappiness(path string, swappiness *uint64) error {
    if swappiness != nil {
        // èŒƒå›´ 0-100ï¼Œå€¼è¶Šå°è¶Šä¸æ„¿æ„ä½¿ç”¨äº¤æ¢ç©ºé—´
        // 0: ç¦ç”¨äº¤æ¢ (é™¤éå†…å­˜ä¸è¶³)
        // 100: ç§¯æä½¿ç”¨äº¤æ¢ç©ºé—´
        if err := cgroups.WriteFile(path, "memory.swappiness", 
            strconv.FormatUint(*swappiness, 10)); err != nil {
            return err
        }
    }
    return nil
}
```

### 3.3 IO èµ„æºæ§åˆ¶

#### A. IO æƒé‡æ§åˆ¶

**Cgroups v1 å®ç°**ï¼š

```go
func (s *BlkioGroup) Set(path string, r *cgroups.Resources) error {
    // æ£€æµ‹å¹¶é€‰æ‹©è°ƒåº¦å™¨ (CFQ æˆ– BFQ)
    s.detectWeightFilenames(path)
    
    // è®¾ç½®å…¨å±€ IO æƒé‡
    if r.BlkioWeight != 0 {
        // èŒƒå›´: 10-1000ï¼Œé»˜è®¤: 500
        if err := cgroups.WriteFile(path, s.weightFilename, 
            strconv.FormatUint(uint64(r.BlkioWeight), 10)); err != nil {
            return err
        }
    }
    
    // è®¾ç½®è®¾å¤‡çº§ IO æƒé‡
    for _, wd := range r.BlkioWeightDevice {
        if wd.Weight != 0 {
            // æ ¼å¼: "major:minor weight"
            weightStr := fmt.Sprintf("%d:%d %d", wd.Major, wd.Minor, wd.Weight)
            if err := cgroups.WriteFile(path, s.weightDeviceFilename, 
                weightStr); err != nil {
                return err
            }
        }
    }
    
    return s.setThrottle(path, r)
}
```

**Cgroups v2 å®ç°**ï¼š

```go
func setIo(dirPath string, r *cgroups.Resources) error {
    // ä¼˜å…ˆå°è¯•ä½¿ç”¨ BFQ è°ƒåº¦å™¨ (æ›´å¥½çš„æ€§èƒ½)
    var bfq *os.File
    if r.BlkioWeight != 0 || len(r.BlkioWeightDevice) > 0 {
        if bfq, err := cgroups.OpenFile(dirPath, "io.bfq.weight", os.O_RDWR); err == nil {
            defer bfq.Close()
        }
    }
    
    // è®¾ç½® IO æƒé‡
    if r.BlkioWeight != 0 {
        if bfq != nil {
            // ä½¿ç”¨ BFQ è°ƒåº¦å™¨
            if _, err := bfq.WriteString(strconv.FormatUint(uint64(r.BlkioWeight), 10)); err != nil {
                return err
            }
        } else {
            // è½¬æ¢ä¸º io.weight å€¼ (ä¸åŒçš„èŒƒå›´)
            v := cgroups.ConvertBlkIOToIOWeightValue(r.BlkioWeight)
            if err := cgroups.WriteFile(dirPath, "io.weight", 
                strconv.FormatUint(v, 10)); err != nil {
                return err
            }
        }
    }
    
    return nil
}

// BlkIO æƒé‡åˆ° IO æƒé‡çš„è½¬æ¢
func ConvertBlkIOToIOWeightValue(blkioWeight uint16) uint64 {
    if blkioWeight == 0 {
        return 0
    }
    // weight = (blkioWeight - 10) * 9999 / 990 + 1
    return uint64((uint64(blkioWeight)-10)*9999/990 + 1)
}
```

#### B. IO é™æµ (Throttling)

```go
// IO å¸¦å®½é™åˆ¶
func setIOThrottle(path string, r *cgroups.Resources) error {
    // è¯»å–å¸¦å®½é™åˆ¶
    for _, td := range r.BlkioThrottleReadBpsDevice {
        throttleStr := fmt.Sprintf("%d:%d %d", td.Major, td.Minor, td.Rate)
        if err := cgroups.WriteFile(path, "blkio.throttle.read_bps_device", 
            throttleStr); err != nil {
            return err
        }
    }
    
    // å†™å…¥å¸¦å®½é™åˆ¶
    for _, td := range r.BlkioThrottleWriteBpsDevice {
        throttleStr := fmt.Sprintf("%d:%d %d", td.Major, td.Minor, td.Rate)  
        if err := cgroups.WriteFile(path, "blkio.throttle.write_bps_device", 
            throttleStr); err != nil {
            return err
        }
    }
    
    // IOPS é™åˆ¶
    for _, td := range r.BlkioThrottleReadIOPSDevice {
        throttleStr := fmt.Sprintf("%d:%d %d", td.Major, td.Minor, td.Rate)
        if err := cgroups.WriteFile(path, "blkio.throttle.read_iops_device", 
            throttleStr); err != nil {
            return err
        }
    }
    
    return nil
}
```

### 3.4 è®¾å¤‡è®¿é—®æ§åˆ¶

#### A. Cgroups v1 è®¾å¤‡æ§åˆ¶ (ç™½åå•æœºåˆ¶)

```go
// è®¾å¤‡è®¿é—®æ§åˆ¶çš„çŠ¶æ€æœºå®ç°
func setV1(path string, r *cgroups.Resources) error {
    // 1. åŠ è½½å½“å‰è®¾å¤‡è®¿é—®çŠ¶æ€
    current, err := loadEmulator(path)
    if err != nil {
        return err
    }
    
    // 2. æ„å»ºç›®æ ‡çŠ¶æ€
    target, err := buildEmulator(r.Devices)
    if err != nil {
        return err
    }
    
    // 3. è®¡ç®—çŠ¶æ€è½¬æ¢è§„åˆ™
    transitionRules, err := current.Transition(target)
    if err != nil {
        return err
    }
    
    // 4. åº”ç”¨è½¬æ¢è§„åˆ™
    for _, rule := range transitionRules {
        file := "devices.deny"
        if rule.Allow {
            file = "devices.allow"
        }
        
        ruleStr := rule.CgroupString()  // æ ¼å¼: "c 1:3 rwm"
        if err := cgroups.WriteFile(path, file, ruleStr); err != nil {
            return fmt.Errorf("failed to write %s to %s: %w", ruleStr, file, err)
        }
    }
    
    // 5. éªŒè¯æœ€ç»ˆçŠ¶æ€
    currentAfter, err := loadEmulator(path)
    if err != nil {
        return err
    }
    
    if !target.IsBlacklist() && !reflect.DeepEqual(currentAfter, target) {
        return errors.New("resulting devices cgroup doesn't precisely match target")
    }
    
    return nil
}
```

**è®¾å¤‡è§„åˆ™æ ¼å¼**ï¼š

```bash
# è®¾å¤‡è§„åˆ™æ ¼å¼: [a|b|c] [major:minor|*] [r][w][m]
# a: all devices, b: block devices, c: character devices  
# major:minor: è®¾å¤‡å·ï¼Œ* è¡¨ç¤ºæ‰€æœ‰
# r: read, w: write, m: mknod

# å…è®¸è®¿é—®æ‰€æœ‰è®¾å¤‡ (å±é™©!)
echo "a *:* rwm" > devices.allow

# å…è®¸è¯»å†™ /dev/null (1:3)
echo "c 1:3 rw" > devices.allow  

# ç¦æ­¢è®¿é—®æ‰€æœ‰å—è®¾å¤‡
echo "b *:* rwm" > devices.deny

# å…è®¸åˆ›å»ºå­—ç¬¦è®¾å¤‡èŠ‚ç‚¹ 
echo "c 5:0 m" > devices.allow  # /dev/tty
```

#### B. Cgroups v2 è®¾å¤‡æ§åˆ¶ (eBPF ç¨‹åº)

```go
// v2 ä½¿ç”¨ eBPF ç¨‹åºè¿›è¡Œè®¾å¤‡è®¿é—®æ§åˆ¶
func setV2(dirPath string, r *cgroups.Resources) error {
    // 1. ç”Ÿæˆ eBPF æŒ‡ä»¤å’Œè®¸å¯è¯
    insts, license, err := deviceFilter(r.Devices)
    if err != nil {
        return err
    }
    
    // 2. æ‰“å¼€ cgroup ç›®å½•æ–‡ä»¶æè¿°ç¬¦
    dirFD, err := unix.Open(dirPath, unix.O_DIRECTORY|unix.O_RDONLY, 0o600)
    if err != nil {
        return fmt.Errorf("cannot get dir FD for %s", dirPath)
    }
    defer unix.Close(dirFD)
    
    // 3. åŠ è½½å’Œé™„åŠ  eBPF ç¨‹åºåˆ° cgroup
    if _, err := loadAttachCgroupDeviceFilter(insts, license, dirFD); err != nil {
        if !canSkipEBPFError(r) {
            return err
        }
        // rootless æ¨¡å¼æˆ–çº¯å…è®¸è§„åˆ™å¯ä»¥å¿½ç•¥ eBPF é”™è¯¯
        logrus.WithError(err).Warn("Failed to load eBPF device filter")
    }
    
    return nil
}

// æ£€æŸ¥æ˜¯å¦å¯ä»¥å¿½ç•¥ eBPF é”™è¯¯
func canSkipEBPFError(r *cgroups.Resources) bool {
    // rootless æ¨¡å¼å…è®¸å¿½ç•¥ eBPF é”™è¯¯
    if userns.RunningInUserNS() {
        return true
    }
    
    // å¦‚æœæ‰€æœ‰è§„åˆ™éƒ½æ˜¯å…è®¸è§„åˆ™ä¸”åŒ…å« rwm æƒé™
    for _, dev := range r.Devices {
        if !dev.Allow || !isRWM(dev.Permissions) {
            return false
        }
    }
    return true
}
```

### 3.5 è¿›ç¨‹æ•°é™åˆ¶ (PIDs)

```go
// é™åˆ¶ cgroup ä¸­çš„è¿›ç¨‹æ•°é‡
func setPids(path string, r *cgroups.Resources) error {
    if r.PidsLimit != 0 {
        var limit string
        if r.PidsLimit > 0 {
            limit = strconv.FormatInt(r.PidsLimit, 10)
        } else {
            limit = "max"  // æ— é™åˆ¶
        }
        
        if err := cgroups.WriteFile(path, "pids.max", limit); err != nil {
            return err
        }
    }
    return nil
}
```

## 4. èµ„æºç»Ÿè®¡å’Œç›‘æ§

### 4.1 ç»Ÿè®¡æ•°æ®ç»“æ„

```go
// ç»¼åˆçš„èµ„æºä½¿ç”¨ç»Ÿè®¡
type Stats struct {
    CpuStats     CpuStats                `json:"cpu_stats"`
    CPUSetStats  CPUSetStats             `json:"cpuset_stats"`
    MemoryStats  MemoryStats             `json:"memory_stats"`
    PidsStats    PidsStats               `json:"pids_stats"`
    BlkioStats   BlkioStats              `json:"blkio_stats"`
    HugetlbStats map[string]HugetlbStats `json:"hugetlb_stats"`
    RdmaStats    RdmaStats               `json:"rdma_stats"`
    MiscStats    map[string]MiscStats    `json:"misc_stats"`
}

// CPU ä½¿ç”¨ç»Ÿè®¡
type CpuStats struct {
    CpuUsage       CpuUsage       `json:"cpu_usage"`
    ThrottlingData ThrottlingData `json:"throttling_data"`
    PSI            *PSIStats      `json:"psi,omitempty"`  // å‹åŠ›å¤±é€Ÿä¿¡æ¯
    BurstData      BurstData      `json:"cpu_burst"`      // çªå‘ä½¿ç”¨æ•°æ®
}

// å†…å­˜ä½¿ç”¨ç»Ÿè®¡
type MemoryStats struct {
    Cache              uint64                `json:"cache"`
    Usage              MemoryData            `json:"usage"`
    SwapUsage          MemoryData            `json:"swap_usage"`
    SwapOnlyUsage      MemoryData            `json:"swap_only_usage"`
    KernelUsage        MemoryData            `json:"kernel_usage"`
    KernelTCPUsage     MemoryData            `json:"kernel_tcp_usage"`
    PageUsageByNUMA    PageUsageByNUMA       `json:"page_usage_by_numa"`
    UseHierarchy       bool                  `json:"use_hierarchy"`
    Stats              map[string]uint64     `json:"stats"`  // è¯¦ç»†ç»Ÿè®¡
    PSI                *PSIStats             `json:"psi,omitempty"`
}

// å‹åŠ›å¤±é€Ÿä¿¡æ¯ (PSI - Pressure Stall Information)
type PSIStats struct {
    Some PSIData `json:"some"` // æŸäº›ä»»åŠ¡å—é˜»
    Full PSIData `json:"full"` // æ‰€æœ‰ä»»åŠ¡å—é˜»  
}

type PSIData struct {
    Avg10  float64 `json:"avg10"`  // 10ç§’å¹³å‡
    Avg60  float64 `json:"avg60"`  // 60ç§’å¹³å‡
    Avg300 float64 `json:"avg300"` // 300ç§’å¹³å‡
    Total  uint64  `json:"total"`  // æ€»è®¡å¾®ç§’
}
```

### 4.2 ç»Ÿè®¡æ•°æ®æ”¶é›†å®ç°

#### Cgroups v1 ç»Ÿè®¡æ”¶é›†

```go
// v1 éœ€è¦ä»å¤šä¸ªå­ç³»ç»Ÿæ”¶é›†ç»Ÿè®¡
func (m *Manager) GetStats() (*cgroups.Stats, error) {
    m.mu.Lock()
    defer m.mu.Unlock()
    
    stats := cgroups.NewStats()
    
    // éå†æ‰€æœ‰å­ç³»ç»Ÿæ”¶é›†ç»Ÿè®¡
    for _, sys := range subsystems {
        path := m.paths[sys.Name()]
        if path == "" {
            continue
        }
        
        if err := sys.GetStats(path, stats); err != nil {
            if os.IsNotExist(errors.Cause(err)) {
                continue  // å­ç³»ç»Ÿä¸å­˜åœ¨ï¼Œè·³è¿‡
            }
            return nil, err
        }
    }
    
    return stats, nil
}

// CPU ç»Ÿè®¡æ”¶é›†ç¤ºä¾‹
func (s *CpuGroup) GetStats(path string, stats *cgroups.Stats) error {
    // CPU ä½¿ç”¨æ—¶é—´ç»Ÿè®¡
    if cpuacctUsage, err := fscommon.GetCgroupParamUint(path, "cpuacct.usage"); err == nil {
        stats.CpuStats.CpuUsage.TotalUsage = cpuacctUsage
    }
    
    // åˆ†æ ¸å¿ƒ CPU ä½¿ç”¨ç»Ÿè®¡
    if percpuUsage, err := fscommon.ParseCgroupFile(path, "cpuacct.usage_percpu"); err == nil {
        for i, usage := range percpuUsage {
            if len(stats.CpuStats.CpuUsage.PercpuUsage) <= i {
                stats.CpuStats.CpuUsage.PercpuUsage = append(stats.CpuStats.CpuUsage.PercpuUsage, usage)
            } else {
                stats.CpuStats.CpuUsage.PercpuUsage[i] = usage
            }
        }
    }
    
    // é™æµç»Ÿè®¡
    if throttledData, err := fscommon.ParseCgroupFile(path, "cpu.stat"); err == nil {
        stats.CpuStats.ThrottlingData.Periods = throttledData["nr_periods"]
        stats.CpuStats.ThrottlingData.ThrottledPeriods = throttledData["nr_throttled"]  
        stats.CpuStats.ThrottlingData.ThrottledTime = throttledData["throttled_time"]
    }
    
    return nil
}
```

#### Cgroups v2 ç»Ÿè®¡æ”¶é›†

```go
// v2 ä»ç»Ÿä¸€è·¯å¾„æ”¶é›†æ‰€æœ‰ç»Ÿè®¡
func (m *Manager) GetStats() (*cgroups.Stats, error) {
    var errs []error
    st := cgroups.NewStats()
    
    // æ”¶é›†å„ç§èµ„æºç»Ÿè®¡
    if err := statPids(m.dirPath, st); err != nil {
        errs = append(errs, err)
    }
    
    if err := statMemory(m.dirPath, st); err != nil && !os.IsNotExist(err) {
        errs = append(errs, err)
    }
    
    if err := statIo(m.dirPath, st); err != nil && !os.IsNotExist(err) {
        errs = append(errs, err)
    }
    
    if err := statCpu(m.dirPath, st); err != nil && !os.IsNotExist(err) {
        errs = append(errs, err)
    }
    
    // æ”¶é›† PSI (å‹åŠ›å¤±é€Ÿä¿¡æ¯)
    if st.CpuStats.PSI, err = statPSI(m.dirPath, "cpu.pressure"); err == nil {
        errs = append(errs, err)
    }
    if st.MemoryStats.PSI, err = statPSI(m.dirPath, "memory.pressure"); err == nil {
        errs = append(errs, err)
    }
    
    return st, nil
}

// PSI ç»Ÿè®¡æ”¶é›†
func statPSI(dirPath, file string) (*cgroups.PSIStats, error) {
    data, err := cgroups.ReadFile(dirPath, file)
    if err != nil {
        return nil, err
    }
    
    psi := &cgroups.PSIStats{}
    
    // è§£ææ ¼å¼: "some avg10=0.00 avg60=0.00 avg300=0.00 total=0"
    lines := strings.Split(string(data), "\n")
    for _, line := range lines {
        if strings.HasPrefix(line, "some ") {
            psi.Some = parsePSIData(line)
        } else if strings.HasPrefix(line, "full ") {
            psi.Full = parsePSIData(line)
        }
    }
    
    return psi, nil
}
```

### 4.3 æ€§èƒ½ç›‘æ§æŒ‡æ ‡è§£è¯»

#### A. CPU ç›‘æ§æŒ‡æ ‡

```go
// CPU ä½¿ç”¨ç‡è®¡ç®—
func calculateCPUPercent(prev, curr *CpuStats) float64 {
    var (
        cpuDelta    = curr.CpuUsage.TotalUsage - prev.CpuUsage.TotalUsage
        systemDelta = curr.SystemUsage - prev.SystemUsage
    )
    
    if systemDelta > 0 && cpuDelta > 0 {
        return (float64(cpuDelta) / float64(systemDelta)) * float64(len(curr.CpuUsage.PercpuUsage)) * 100.0
    }
    return 0.0
}

// é™æµåˆ†æ
func analyzeCPUThrottling(stats *CpuStats) {
    if stats.ThrottlingData.Periods > 0 {
        throttlePercent := float64(stats.ThrottlingData.ThrottledPeriods) / float64(stats.ThrottlingData.Periods) * 100
        fmt.Printf("CPU Throttling: %.2f%% of periods throttled\n", throttlePercent)
        fmt.Printf("Total throttled time: %d ns\n", stats.ThrottlingData.ThrottledTime)
    }
}
```

#### B. å†…å­˜ç›‘æ§æŒ‡æ ‡

```go
// å†…å­˜ä½¿ç”¨åˆ†æ
func analyzeMemoryUsage(stats *MemoryStats) {
    fmt.Printf("Memory Usage: %d / %d bytes (%.2f%%)\n", 
        stats.Usage.Usage, stats.Usage.Limit,
        float64(stats.Usage.Usage)/float64(stats.Usage.Limit)*100)
    
    fmt.Printf("Memory Cache: %d bytes\n", stats.Cache)
    fmt.Printf("Memory RSS: %d bytes\n", stats.Stats["rss"])
    fmt.Printf("Memory Swap: %d / %d bytes\n", stats.SwapUsage.Usage, stats.SwapUsage.Limit)
    
    // å†…å­˜å‹åŠ›åˆ†æ
    if stats.PSI != nil {
        fmt.Printf("Memory Pressure: some=%.2f%%, full=%.2f%%\n",
            stats.PSI.Some.Avg60, stats.PSI.Full.Avg60)
    }
}
```

## 5. é«˜çº§ç‰¹æ€§å’Œä¼˜åŒ–

### 5.1 å±‚æ¬¡ç»“æ„ç®¡ç†

```go
// cgroup å±‚æ¬¡ç»“æ„çš„åˆ›å»ºå’Œç®¡ç†
type Manager struct {
    mu      sync.Mutex
    cgroups *cgroups.Cgroup
    paths   map[string]string  // v1: å¤šè·¯å¾„æ˜ å°„
    dirPath string            // v2: å•ä¸€è·¯å¾„
}

// åˆ›å»º cgroup å±‚æ¬¡ç»“æ„
func (m *Manager) Apply(pid int) error {
    // 1. åˆ›å»º cgroup ç›®å½•ç»“æ„
    if err := m.createCgroupPath(); err != nil {
        return err
    }
    
    // 2. è®¾ç½®èµ„æºé™åˆ¶
    if err := m.Set(m.cgroups.Resources); err != nil {
        return err
    }
    
    // 3. å°†è¿›ç¨‹åŠ å…¥ cgroup
    if err := m.addProcess(pid); err != nil {
        return err  
    }
    
    return nil
}

func (m *Manager) createCgroupPath() error {
    // v1 éœ€è¦ä¸ºæ¯ä¸ªå­ç³»ç»Ÿåˆ›å»ºè·¯å¾„
    if !cgroups.IsCgroup2UnifiedMode() {
        for subsys, path := range m.paths {
            if err := os.MkdirAll(path, 0755); err != nil {
                return fmt.Errorf("failed to create cgroup path %s: %w", path, err)
            }
        }
        return nil
    }
    
    // v2 åªéœ€åˆ›å»ºå•ä¸€è·¯å¾„
    return os.MkdirAll(m.dirPath, 0755)
}
```

### 5.2 åŠ¨æ€èµ„æºè°ƒæ•´

```go
// è¿è¡Œæ—¶åŠ¨æ€è°ƒæ•´èµ„æºé™åˆ¶
func (m *Manager) UpdateResources(r *cgroups.Resources) error {
    m.mu.Lock()
    defer m.mu.Unlock()
    
    // éªŒè¯æ–°çš„èµ„æºé…ç½®
    if err := validateResources(r); err != nil {
        return err
    }
    
    // åº”ç”¨æ–°çš„èµ„æºé™åˆ¶
    if err := m.Set(r); err != nil {
        return err
    }
    
    // æ›´æ–°å†…éƒ¨é…ç½®
    m.cgroups.Resources = r
    
    return nil
}

func validateResources(r *cgroups.Resources) error {
    // å†…å­˜é™åˆ¶ä¸èƒ½ä½äºå½“å‰ä½¿ç”¨é‡
    if r.Memory > 0 {
        // æ£€æŸ¥å½“å‰å†…å­˜ä½¿ç”¨
        // ...
    }
    
    // CPU é…é¢åˆç†æ€§æ£€æŸ¥  
    if r.CpuQuota > 0 && r.CpuPeriod > 0 {
        cpuRatio := float64(r.CpuQuota) / float64(r.CpuPeriod)
        if cpuRatio > float64(runtime.NumCPU()) {
            return fmt.Errorf("CPU quota %.2f exceeds available CPUs %d", 
                cpuRatio, runtime.NumCPU())
        }
    }
    
    return nil
}
```

### 5.3 Rootless å®¹å™¨æ”¯æŒ

```go
// Rootless æ¨¡å¼çš„ç‰¹æ®Šå¤„ç†
func NewRootlessManager(config *cgroups.Cgroup) (cgroups.Manager, error) {
    // æ£€æŸ¥ cgroups å§”æ‰˜
    if !isValidDelegate() {
        return nil, errors.New("insufficient cgroups delegation for rootless")
    }
    
    // Rootless æ¨¡å¼ä¸‹çš„è·¯å¾„è°ƒæ•´
    userSlice, err := getUserSlice()
    if err != nil {
        return nil, err
    }
    
    config.Path = filepath.Join(userSlice, config.Path)
    
    if cgroups.IsCgroup2UnifiedMode() {
        return fs2.NewManager(config, config.Path)
    } else {
        // v1 rootless æ”¯æŒæœ‰é™
        return nil, errors.New("cgroups v1 rootless support is limited")
    }
}

func isValidDelegate() bool {
    // æ£€æŸ¥ç”¨æˆ·æ˜¯å¦æœ‰è¶³å¤Ÿçš„ cgroups å§”æ‰˜æƒé™
    delegateFile := "/sys/fs/cgroup/cgroup.subtree_control"
    if data, err := os.ReadFile(delegateFile); err == nil {
        return strings.Contains(string(data), "memory") && 
               strings.Contains(string(data), "cpu")
    }
    return false
}
```

### 5.4 æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

#### A. æ‰¹é‡æ“ä½œ

```go
// æ‰¹é‡è®¾ç½®å¤šä¸ªèµ„æºå‚æ•°ï¼Œå‡å°‘ç³»ç»Ÿè°ƒç”¨
func (m *Manager) SetBatch(r *cgroups.Resources) error {
    operations := []func() error{
        func() error { return setCpu(m.path, r) },
        func() error { return setMemory(m.path, r) },
        func() error { return setIO(m.path, r) },
        func() error { return setPids(m.path, r) },
    }
    
    // å¹¶å‘æ‰§è¡Œï¼Œä½†è¦å¤„ç†ä¾èµ–å…³ç³»
    for _, op := range operations {
        if err := op(); err != nil {
            return err
        }
    }
    
    return nil
}
```

#### B. ç¼“å­˜æœºåˆ¶

```go
// ç»Ÿè®¡æ•°æ®ç¼“å­˜ï¼Œé¿å…é¢‘ç¹è¯»å–æ–‡ä»¶
type cachedStats struct {
    stats     *cgroups.Stats
    timestamp time.Time
    ttl       time.Duration
}

func (m *Manager) GetStatsCached() (*cgroups.Stats, error) {
    if m.cache != nil && time.Since(m.cache.timestamp) < m.cache.ttl {
        return m.cache.stats, nil
    }
    
    stats, err := m.GetStats()
    if err != nil {
        return nil, err
    }
    
    m.cache = &cachedStats{
        stats:     stats,
        timestamp: time.Now(),
        ttl:       time.Second * 5,  // 5ç§’ç¼“å­˜
    }
    
    return stats, nil
}
```

## 6. å®è·µç»ƒä¹ 

### 6.1 åŸºç¡€èµ„æºé™åˆ¶å®éªŒ

```bash
#!/bin/bash
# å®éªŒ 1: CPU é™åˆ¶æµ‹è¯•

# åˆ›å»ºæµ‹è¯• cgroup
sudo mkdir -p /sys/fs/cgroup/cpu/test-cpu
echo $$ | sudo tee /sys/fs/cgroup/cpu/test-cpu/cgroup.procs

# é™åˆ¶ä¸º 0.5 ä¸ª CPU æ ¸å¿ƒ
echo 100000 | sudo tee /sys/fs/cgroup/cpu/test-cpu/cpu.cfs_period_us
echo 50000 | sudo tee /sys/fs/cgroup/cpu/test-cpu/cpu.cfs_quota_us

# è¿è¡Œ CPU å¯†é›†ä»»åŠ¡å¹¶è§‚å¯Ÿé™åˆ¶æ•ˆæœ
stress --cpu 4 --timeout 30s &

# ç›‘æ§ CPU ä½¿ç”¨
watch -n 1 "cat /sys/fs/cgroup/cpu/test-cpu/cpuacct.usage && top -p \$!"
```

```bash
#!/bin/bash  
# å®éªŒ 2: å†…å­˜é™åˆ¶æµ‹è¯•

# åˆ›å»ºå†…å­˜é™åˆ¶ cgroup
sudo mkdir -p /sys/fs/cgroup/memory/test-memory
echo $$ | sudo tee /sys/fs/cgroup/memory/test-memory/cgroup.procs

# é™åˆ¶å†…å­˜ä¸º 100MB
echo 104857600 | sudo tee /sys/fs/cgroup/memory/test-memory/memory.limit_in_bytes

# å°è¯•åˆ†é… 200MB å†…å­˜ (åº”è¯¥è¢« OOM killer ç»ˆæ­¢)
stress --vm 1 --vm-bytes 200M --timeout 10s

# æ£€æŸ¥ OOM ç»Ÿè®¡
cat /sys/fs/cgroup/memory/test-memory/memory.oom_control
```

### 6.2 ç›‘æ§è„šæœ¬å¼€å‘

```bash
#!/bin/bash
# cgroup èµ„æºç›‘æ§è„šæœ¬

CGROUP_PATH="/sys/fs/cgroup"
CONTAINER_PATH="$CGROUP_PATH/system.slice/docker-*.scope"

monitor_container() {
    local container_path="$1"
    local container_name=$(basename "$container_path" | cut -d'-' -f2 | cut -d'.' -f1)
    
    echo "=== Container: $container_name ==="
    
    # CPU ç»Ÿè®¡
    if [[ -f "$container_path/cpu.stat" ]]; then
        echo "CPU Stats:"
        grep -E "(usage_usec|throttled)" "$container_path/cpu.stat" | sed 's/^/  /'
    fi
    
    # å†…å­˜ç»Ÿè®¡  
    if [[ -f "$container_path/memory.current" ]]; then
        echo "Memory Usage: $(cat $container_path/memory.current) bytes"
        echo "Memory Limit: $(cat $container_path/memory.max)"
    fi
    
    # IO ç»Ÿè®¡
    if [[ -f "$container_path/io.stat" ]]; then
        echo "IO Stats:"
        head -3 "$container_path/io.stat" | sed 's/^/  /'
    fi
    
    echo
}

# ç›‘æ§æ‰€æœ‰å®¹å™¨
while true; do
    for container_path in $CONTAINER_PATH; do
        [[ -d "$container_path" ]] && monitor_container "$container_path"
    done
    sleep 5
done
```

### 6.3 è‡ªå®šä¹‰èµ„æºæ§åˆ¶

```go
// è‡ªå®šä¹‰èµ„æºç®¡ç†å™¨ç¤ºä¾‹
package main

import (
    "fmt"
    "github.com/opencontainers/cgroups"
    "github.com/opencontainers/cgroups/fs2"
)

func main() {
    // åˆ›å»ºè‡ªå®šä¹‰ cgroup é…ç½®
    cgroupConfig := &cgroups.Cgroup{
        Path: "custom-test",
        Resources: &cgroups.Resources{
            Memory: 128 * 1024 * 1024,  // 128MB
            CpuWeight: 100,             // CPU æƒé‡
            CpuQuota: 50000,           // 0.5 CPU æ ¸å¿ƒ
            CpuPeriod: 100000,         // 100ms å‘¨æœŸ
        },
    }
    
    // åˆ›å»ºç®¡ç†å™¨ (è‡ªåŠ¨æ£€æµ‹ v1/v2)
    manager, err := fs2.NewManager(cgroupConfig, cgroupConfig.Path)
    if err != nil {
        panic(err)
    }
    
    // åº”ç”¨é…ç½®åˆ°å½“å‰è¿›ç¨‹
    if err := manager.Apply(os.Getpid()); err != nil {
        panic(err)
    }
    
    fmt.Println("Cgroup applied successfully!")
    
    // è¿è¡Œä¸€äº›å·¥ä½œè´Ÿè½½
    doWork()
    
    // è·å–ç»Ÿè®¡ä¿¡æ¯
    stats, err := manager.GetStats()
    if err != nil {
        panic(err)
    }
    
    fmt.Printf("CPU Usage: %d ns\n", stats.CpuStats.CpuUsage.TotalUsage)
    fmt.Printf("Memory Usage: %d bytes\n", stats.MemoryStats.Usage.Usage)
    
    // æ¸…ç†
    if err := manager.Destroy(); err != nil {
        fmt.Printf("Failed to cleanup: %v\n", err)
    }
}

func doWork() {
    // æ¨¡æ‹Ÿä¸€äº› CPU å’Œå†…å­˜ä½¿ç”¨
    data := make([]byte, 50*1024*1024) // 50MB
    for i := 0; i < len(data); i++ {
        data[i] = byte(i % 256)
    }
    
    // CPU å¯†é›†è®¡ç®—
    sum := 0
    for i := 0; i < 10000000; i++ {
        sum += i
    }
    
    fmt.Printf("Work completed, sum: %d\n", sum)
}
```

## 7. æ•…éšœæ’é™¤å’Œè°ƒè¯•

### 7.1 å¸¸è§é—®é¢˜è¯Šæ–­

#### æƒé™é—®é¢˜

```bash
# æ£€æŸ¥ cgroup æŒ‚è½½æƒ…å†µ
mount | grep cgroup

# æ£€æŸ¥ cgroup ç‰ˆæœ¬
stat -fc %T /sys/fs/cgroup/
# cgroup2fs = v2, tmpfs = v1

# æ£€æŸ¥ç”¨æˆ·æƒé™
ls -la /sys/fs/cgroup/user.slice/user-$(id -u).slice/

# æ£€æŸ¥ systemd å§”æ‰˜
systemctl --user show-environment
```

#### èµ„æºé™åˆ¶ä¸ç”Ÿæ•ˆ

```bash
# æ£€æŸ¥æ˜¯å¦æ­£ç¡®è®¾ç½®
echo "è®¾ç½®çš„é™åˆ¶:"
cat /sys/fs/cgroup/memory/test/memory.limit_in_bytes

echo "å½“å‰ä½¿ç”¨:"  
cat /sys/fs/cgroup/memory/test/memory.usage_in_bytes

echo "è¿›ç¨‹åˆ—è¡¨:"
cat /sys/fs/cgroup/memory/test/cgroup.procs

# æ£€æŸ¥å†…æ ¸æ”¯æŒ
grep CONFIG_MEMCG /boot/config-$(uname -r)
```

### 7.2 æ€§èƒ½åˆ†æå·¥å…·

```bash
# ä½¿ç”¨ systemd-cgtop ç›‘æ§
systemd-cgtop

# ä½¿ç”¨ htop æŸ¥çœ‹ cgroup ä¿¡æ¯
htop -t  # æ˜¾ç¤ºè¿›ç¨‹æ ‘

# ä½¿ç”¨ perf åˆ†æ cgroup æ€§èƒ½
perf record -g -e cpu-cycles --cgroup=/sys/fs/cgroup/test ./workload
perf report
```

## 8. æ€è€ƒé¢˜

### 8.1 æ¶æ„è®¾è®¡æ€è€ƒ

1. **åŒç‰ˆæœ¬æ¶æ„**: ä¸ºä»€ä¹ˆ runc éœ€è¦åŒæ—¶æ”¯æŒ cgroups v1 å’Œ v2ï¼Ÿä¸¤ä¸ªç‰ˆæœ¬èƒ½å¦ç»Ÿä¸€ï¼Ÿ

2. **èµ„æºå†²çªå¤„ç†**: å½“ CPU é…é¢å’Œæƒé‡åŒæ—¶è®¾ç½®æ—¶ï¼Œå†…æ ¸å¦‚ä½•å¤„ç†ä¼˜å…ˆçº§ï¼Ÿ

3. **å†…å­˜äº¤æ¢ç­–ç•¥**: ä¸ºä»€ä¹ˆå†…å­˜é™åˆ¶çš„è®¾ç½®é¡ºåºå¾ˆé‡è¦ï¼Ÿå¦‚ä½•é¿å…è®¾ç½®å†²çªï¼Ÿ

### 8.2 æ€§èƒ½ä¼˜åŒ–æ€è€ƒ

4. **ç»Ÿè®¡æ”¶é›†å¼€é”€**: é¢‘ç¹è¯»å– cgroup ç»Ÿè®¡æ–‡ä»¶å¯¹æ€§èƒ½æœ‰ä»€ä¹ˆå½±å“ï¼Ÿå¦‚ä½•ä¼˜åŒ–ï¼Ÿ

5. **æ‰¹é‡æ“ä½œ**: å“ªäº› cgroup æ“ä½œå¯ä»¥æ‰¹é‡æ‰§è¡Œï¼Ÿå¦‚ä½•è®¾è®¡æ‰¹é‡æ¥å£ï¼Ÿ

6. **ç¼“å­˜ç­–ç•¥**: cgroup è·¯å¾„å’Œæ–‡ä»¶æè¿°ç¬¦åº”è¯¥å¦‚ä½•ç¼“å­˜ï¼Ÿä»€ä¹ˆæ—¶å€™å¤±æ•ˆï¼Ÿ

### 8.3 å®é™…åº”ç”¨æ€è€ƒ

7. **åŠ¨æ€è°ƒæ•´**: å¦‚ä½•åœ¨ä¸é‡å¯å®¹å™¨çš„æƒ…å†µä¸‹å®‰å…¨åœ°è°ƒæ•´èµ„æºé™åˆ¶ï¼Ÿ

8. **èµ„æºè¶…å”®**: åœ¨èµ„æºè¶…å”®çš„æƒ…å†µä¸‹ï¼Œå¦‚ä½•è®¾è®¡åˆç†çš„èµ„æºåˆ†é…ç­–ç•¥ï¼Ÿ

9. **å¤šç§Ÿæˆ·éš”ç¦»**: å¦‚ä½•ä½¿ç”¨ cgroups å®ç°å¤šç§Ÿæˆ·ä¹‹é—´çš„èµ„æºéš”ç¦»ï¼Ÿ

## 9. æ‰©å±•é˜…è¯»

### 9.1 å†…æ ¸æ–‡æ¡£

- [Control Group v2](https://www.kernel.org/doc/Documentation/admin-guide/cgroup-v2.rst)
- [Control Group v1](https://www.kernel.org/doc/Documentation/cgroup-v1/)
- [CPU Bandwidth Control](https://www.kernel.org/doc/Documentation/scheduler/sched-bwc.txt)
- [Memory Resource Controller](https://www.kernel.org/doc/Documentation/cgroup-v1/memory.txt)

### 9.2 å®è·µæŒ‡å—

- [Cgroups, namespaces and beyond](https://www.slideshare.net/jpetazzo/cgroups-namespaces-and-beyond-what-are-containers-made-from-dockercon-europe-2015)
- [Understanding cgroups](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/managing_monitoring_and_updating_the_kernel/using-control-groups_managing-monitoring-and-updating-the-kernel)
- [Systemd and cgroups](https://systemd.io/CGROUP_DELEGATION/)

### 9.3 å·¥å…·å’Œç›‘æ§

- [cAdvisor - Container monitoring](https://github.com/google/cadvisor)  
- [systemd-cgtop](https://www.freedesktop.org/software/systemd/man/systemd-cgtop.html)
- [cgroupspy - Python cgroups interface](https://github.com/cloudera/cgroupspy)

## ğŸ¯ æ¨¡å—æ€»ç»“

é€šè¿‡æœ¬æ¨¡å—çš„å­¦ä¹ ï¼Œä½ åº”è¯¥å·²ç»æŒæ¡äº†ï¼š

âœ… **Cgroups åŸºç¡€æ¶æ„**ï¼šç†è§£ v1/v2 å·®å¼‚å’Œå±‚æ¬¡ç»“æ„ç®¡ç†  
âœ… **èµ„æºæ§åˆ¶æœºåˆ¶**ï¼šæŒæ¡ CPUã€å†…å­˜ã€IOã€è®¾å¤‡æ§åˆ¶çš„å®ç°åŸç†  
âœ… **ç»Ÿè®¡ç›‘æ§ç³»ç»Ÿ**ï¼šç†è§£èµ„æºä½¿ç”¨ç»Ÿè®¡å’Œæ€§èƒ½æŒ‡æ ‡åˆ†æ  
âœ… **é«˜çº§ç‰¹æ€§åº”ç”¨**ï¼šæŒæ¡åŠ¨æ€è°ƒæ•´ã€Rootless æ”¯æŒç­‰é«˜çº§åŠŸèƒ½  
âœ… **æ•…éšœæ’é™¤èƒ½åŠ›**ï¼šå…·å¤‡ cgroups é—®é¢˜è¯Šæ–­å’Œæ€§èƒ½è°ƒä¼˜æŠ€èƒ½  

**ä¸‹ä¸€æ­¥**: è¿›å…¥ [æ¨¡å— 5: æ–‡ä»¶ç³»ç»Ÿä¸æŒ‚è½½ç®¡ç†](./05-æ–‡ä»¶ç³»ç»Ÿä¸æŒ‚è½½ç®¡ç†.md)ï¼Œå­¦ä¹ å®¹å™¨æ–‡ä»¶ç³»ç»Ÿéš”ç¦»å’ŒæŒ‚è½½æœºåˆ¶ã€‚